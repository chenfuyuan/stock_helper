# 项目业务优化建议（暂存）

> 本文档为架构评审产出的业务优化建议汇总，供后续规划与落地参考。**不置于 OpenSpec 目录下**，仅为暂存。

---

## 一、当前架构总览

```
┌──────────────────────────────────────────────────────────────────────┐
│                         Coordinator (LangGraph)                       │
│  POST /research → 并行专家 → aggregator → debate → judge → 响应      │
└─────────┬──────────────┬──────────────┬──────────────┬───────────────┘
          │              │              │              │
          ▼              ▼              ▼              ▼
   ┌──────────┐   ┌──────────┐   ┌──────────┐   ┌──────────┐
   │ Research  │   │  Debate  │   │  Judge   │   │ data_eng │
   │ (5专家)   │   │(Bull/Bear│   │(Verdict) │   │(行情/财报)│
   │          │   │→Resolve) │   │          │   │          │
   └──────────┘   └──────────┘   └──────────┘   └──────────┘
```

---

## 二、七项主要业务优化建议

### 1. 辩论机制过于单薄 — 缺乏「多轮博弈」与「交叉质证」

**现状**：

```
Bull Advocate ──┐
                ├──→ Resolution Judge → 输出
Bear Advocate ──┘
```

当前辩论是 **单轮、无反驳** 的。Bull 和 Bear 并行生成各自论点，然后 Resolution 直接裁决。多空双方 **从未互相看到对方的论点**。

**问题**：本质是「两份独立报告 + 一个汇总」，而非真正辩论。真实投研会议中，多空会听到对方论点后反驳、修正或坚持置信度，经 2–3 轮后论点收敛或分歧更尖锐。

**优化建议**：

```
Round 1: Bull 论点 ←→ Bear 论点（独立生成）
Round 2: Bull 反驳 Bear（看到 Bear 论点后）←→ Bear 反驳 Bull
Round 3 (可选): 最终陈词（双方看到反驳后的修正论点）
         ↓
Resolution: 基于全部轮次的论点裁决
```

多轮带来的价值：**置信度校准更真实**——Bull 的关键论据被有效反驳后，其置信度应下降，目前完全缺失。

---

### 2. Judge 裁决缺少「Research 原始数据」上下文

**现状**：Judge 收到的 `JudgeInput` 只有辩论的结论级摘要（direction、confidence、bull_thesis、bear_thesis 等），看不到技术指标、估值分位、财务评分、宏观维度等具体数据。

**问题**：裁决层缺少做出仓位和止损决策所需的量化输入；`stop_loss`、`take_profit` 由 LLM 生成但 LLM 连当前股价和支撑位都不知道。

**优化建议**：

- 向 `JudgeInput` 注入 **关键量化摘要**（不必全量原始数据）：
  - 当前价格 / 关键支撑阻力位 / ATR
  - PE/PB 历史分位
  - 财务评分
- 让 Judge 的 `stop_loss` / `take_profit` / `entry_strategy` 能基于**实际数值**输出。

---

### 3. 专家间缺乏「信息共享」— 各专家是信息孤岛

**现状**：五个专家完全并行、互不知晓对方分析结果。

**问题**：真实投研中分析师会交叉参考（例如技术面在宏观紧缩时更保守、估值在发现负面催化剂时调低假设）。

**优化建议**：考虑 **两阶段研究**：

```
Phase 1: 五专家并行 → 输出初步报告
Phase 2: 每位专家看到其他专家的摘要 → 修正/补充自己的观点
                ↓
             汇总输入辩论
```

Phase 2 不需重做完整分析，只需让 LLM 看到交叉信息后做一次 **校准**（类似 Multi-Agent 的 Reflection 模式）。

---

### 4. 证据链缺乏「可验证性」— LLM 幻觉风险不受控

**现状**：Prompt 要求「证据驱动」，但代码层 **没有验证** LLM 是否真的引用了输入数据。若 LLM 声称「RSI 达到 82 进入超买区」而实际 RSI 为 55，系统无法发现。

**优化建议**：

- **后验证**：在 output_parser 层增加轻量级 `evidence_validator`，交叉检查关键数值引用。
- **置信度自动调整**：若 LLM 置信度高但引用数据少，自动下调。
- **Hallucination Score**：计算输出中提到的具体数字与输入数据的匹配率，作为质量指标。

---

### 5. 缺少「历史决策追踪」— 无法评估系统准确性

**现状**：每次分析为一次性调用，结果返回后未持久化。

**问题**：无法回答「过去推荐的股票表现如何」、无法回测、无法对比专家准确率或做动态权重调整。

**优化建议**：新增 Bounded Context（如 `track_record` / `portfolio_tracker`）：

- 持久化每次 verdict（含时间戳）。
- 定时跟踪推荐标的的后续表现。
- 计算各维度准确率（专家级 / 辩论级）。
- 生成「投资绩效报告」。
- 为动态权重提供历史数据。

---

### 6. 专家权重静态且均等 — 缺乏「动态信任度」

**现状**：五位专家在辩论阶段被同等对待。

**问题**：不同市场环境和标的类型下，各专家重要性不同（周期股 vs 成长股 vs 游资票；历史准确率差异）。

**优化建议**：

- 引入 **专家置信度加权机制**，在 Debate 输入或 Resolution 阶段考虑：
  - 标的特征（行业、市值、波动率）→ 先验权重。
  - 历史预测准确率 → 后验权重（依赖 #5 的 TrackRecord）。

---

### 7. Prompt 工程可优化 — 缺少 Few-shot 和 Chain-of-Thought

**现状**：所有 Prompt 为零样本、未显式要求推理步骤链。

**可改进点**：

| 维度           | 现状     | 建议                                           |
|----------------|----------|------------------------------------------------|
| Few-shot 示例  | 无       | 为每个 Agent 加入 1–2 个高质量示例输出          |
| Chain-of-Thought | 隐式   | 显式要求 `reasoning_steps` 字段                |
| 自我校验       | 无       | Prompt 尾部加入「请检查输出是否引用输入数据」   |
| 字段约束       | 有       | 增加值域校验描述（如 confidence 无强证据时不超 0.8） |
| 上下文窗口利用 | 全量灌入 | 对大体量数据做智能截取/摘要                    |

---

## 三、优化路线图建议（按投入产出比）

| 优先级 | 优化点                     | 难度 | 业务价值 |
|--------|----------------------------|------|----------|
| P0     | #2 Judge 注入量化上下文     | 低   | 高 — 立刻提升裁决质量 |
| P0     | #7 Prompt Few-shot 增强     | 低   | 高 — 提升输出一致性   |
| P1     | #4 证据链后验证             | 中   | 高 — 降低幻觉风险     |
| P1     | #1 多轮辩论机制             | 中   | 高 — 核心差异化能力   |
| P2     | #5 历史决策追踪             | 中   | 中 — 闭环反馈必备     |
| P2     | #3 专家间信息共享(Reflection) | 中   | 中 — 提升分析深度     |
| P3     | #6 动态专家权重             | 高   | 中 — 依赖 #5 数据积累 |

---

## 四、总结

初版已具备：架构分层清晰、DDD 合规、LangGraph 编排灵活、Prompt 外部化与解析器统一、完整的「采集 → 辩论 → 裁决」流水线。

核心差距：当前更接近「五份独立报告 + 汇总」，而非真正的「团队协作与对抗」。要实现仿生投研团队，需要让信息**流动**起来——专家间交叉校验、多空真正博弈、裁决者拿到量化上下文、并通过历史追踪形成正反馈。

---

*文档生成后仅作暂存，不纳入 OpenSpec 变更流程。*
